{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print your name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise by: Benjam.Alander\n"
     ]
    }
   ],
   "source": [
    "## Your code here \n",
    "print(\"Exercise by: Benjam.Alander\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.11/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.11/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sukunimi</th>\n",
       "      <th>Yhteensä</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Korhonen</td>\n",
       "      <td>21655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virtanen</td>\n",
       "      <td>20879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mäkinen</td>\n",
       "      <td>19320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nieminen</td>\n",
       "      <td>19117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mäkelä</td>\n",
       "      <td>18409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sukunimi  Yhteensä\n",
       "0  Korhonen     21655\n",
       "1  Virtanen     20879\n",
       "2   Mäkinen     19320\n",
       "3  Nieminen     19117\n",
       "4    Mäkelä     18409"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = './data/sukunimitilasto-2024-02-01-dvv.xlsx'\n",
    "surnames_df = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "surnames_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5000 / 100000 (5.00%)\n",
      "Time elapsed: 3m 27.16s\n",
      "Current loss: 0.7100\n",
      "Name: Kupiainen / Predicted: Finnish ✓\n",
      "Accuracy over last 100 samples: 41.00%\n",
      "\n",
      "Iteration: 10000 / 100000 (10.00%)\n",
      "Time elapsed: 6m 54.87s\n",
      "Current loss: 2.1812\n",
      "Name: Giang / Predicted: Korean ✗ (Vietnamese)\n",
      "Accuracy over last 100 samples: 44.00%\n",
      "\n",
      "Iteration: 15000 / 100000 (15.00%)\n",
      "Time elapsed: 10m 18.57s\n",
      "Current loss: 1.1329\n",
      "Name: Lang / Predicted: Korean ✗ (Chinese)\n",
      "Accuracy over last 100 samples: 35.00%\n",
      "\n",
      "Iteration: 20000 / 100000 (20.00%)\n",
      "Time elapsed: 13m 45.36s\n",
      "Current loss: 1.8103\n",
      "Name: Perevuznik / Predicted: Russian ✗ (Czech)\n",
      "Accuracy over last 100 samples: 48.00%\n",
      "\n",
      "Iteration: 25000 / 100000 (25.00%)\n",
      "Time elapsed: 17m 12.18s\n",
      "Current loss: 1.7337\n",
      "Name: Serafim / Predicted: Portuguese ✓\n",
      "Accuracy over last 100 samples: 42.00%\n",
      "\n",
      "Iteration: 30000 / 100000 (30.00%)\n",
      "Time elapsed: 20m 36.89s\n",
      "Current loss: 2.4847\n",
      "Name: Piovene / Predicted: French ✗ (Italian)\n",
      "Accuracy over last 100 samples: 51.00%\n",
      "\n",
      "Iteration: 35000 / 100000 (35.00%)\n",
      "Time elapsed: 23m 59.48s\n",
      "Current loss: 2.7474\n",
      "Name: Torisei / Predicted: Italian ✗ (Japanese)\n",
      "Accuracy over last 100 samples: 47.00%\n",
      "\n",
      "Iteration: 40000 / 100000 (40.00%)\n",
      "Time elapsed: 27m 22.97s\n",
      "Current loss: 0.8715\n",
      "Name: Sauvageon / Predicted: French ✓\n",
      "Accuracy over last 100 samples: 46.00%\n",
      "\n",
      "Iteration: 45000 / 100000 (45.00%)\n",
      "Time elapsed: 30m 48.56s\n",
      "Current loss: 0.1909\n",
      "Name: Krakowski / Predicted: Polish ✓\n",
      "Accuracy over last 100 samples: 41.00%\n",
      "\n",
      "Iteration: 50000 / 100000 (50.00%)\n",
      "Time elapsed: 34m 12.25s\n",
      "Current loss: 1.7470\n",
      "Name: Kanaan / Predicted: Irish ✗ (Arabic)\n",
      "Accuracy over last 100 samples: 36.00%\n",
      "\n",
      "Iteration: 55000 / 100000 (55.00%)\n",
      "Time elapsed: 37m 37.18s\n",
      "Current loss: 1.7385\n",
      "Name: Hull / Predicted: English ✓\n",
      "Accuracy over last 100 samples: 45.00%\n",
      "\n",
      "Iteration: 60000 / 100000 (60.00%)\n",
      "Time elapsed: 41m 3.46s\n",
      "Current loss: 0.2722\n",
      "Name: Escamilla / Predicted: Spanish ✓\n",
      "Accuracy over last 100 samples: 47.00%\n",
      "\n",
      "Iteration: 65000 / 100000 (65.00%)\n",
      "Time elapsed: 44m 27.96s\n",
      "Current loss: 2.2545\n",
      "Name: Dempko / Predicted: Russian ✗ (Czech)\n",
      "Accuracy over last 100 samples: 39.00%\n",
      "\n",
      "Iteration: 70000 / 100000 (70.00%)\n",
      "Time elapsed: 47m 52.37s\n",
      "Current loss: 1.2455\n",
      "Name: Klerks / Predicted: Czech ✗ (Dutch)\n",
      "Accuracy over last 100 samples: 48.00%\n",
      "\n",
      "Iteration: 75000 / 100000 (75.00%)\n",
      "Time elapsed: 51m 15.86s\n",
      "Current loss: 0.5514\n",
      "Name: Palmeiro / Predicted: Portuguese ✓\n",
      "Accuracy over last 100 samples: 54.00%\n",
      "\n",
      "Iteration: 80000 / 100000 (80.00%)\n",
      "Time elapsed: 54m 40.66s\n",
      "Current loss: 1.2776\n",
      "Name: Reilly / Predicted: Scottish ✗ (Irish)\n",
      "Accuracy over last 100 samples: 34.00%\n",
      "\n",
      "Iteration: 85000 / 100000 (85.00%)\n",
      "Time elapsed: 58m 4.37s\n",
      "Current loss: 0.6434\n",
      "Name: Iseya / Predicted: Japanese ✓\n",
      "Accuracy over last 100 samples: 53.00%\n",
      "\n",
      "Iteration: 90000 / 100000 (90.00%)\n",
      "Time elapsed: 61m 27.76s\n",
      "Current loss: 0.1162\n",
      "Name: Poletti / Predicted: Italian ✓\n",
      "Accuracy over last 100 samples: 52.00%\n",
      "\n",
      "Iteration: 95000 / 100000 (95.00%)\n",
      "Time elapsed: 64m 52.98s\n",
      "Current loss: 1.0169\n",
      "Name: Cao / Predicted: Vietnamese ✓\n",
      "Accuracy over last 100 samples: 42.00%\n",
      "\n",
      "Iteration: 100000 / 100000 (100.00%)\n",
      "Time elapsed: 68m 15.77s\n",
      "Current loss: 0.9423\n",
      "Name: Kelly / Predicted: Scottish ✓\n",
      "Accuracy over last 100 samples: 46.00%\n",
      "\n",
      "Accuracy on Finnish surnames: 68.32%\n",
      "The model predicts your surname (Alander) as: Arabic\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "surnames_df = pd.read_excel(file_path)\n",
    "\n",
    "# Filter surnames with more than 1000 occurrences\n",
    "surnames = surnames_df[surnames_df['Yhteensä'] > 1000]['Sukunimi'].tolist()\n",
    "\n",
    "# Helper functions to read category files\n",
    "def findFiles(path):\n",
    "    return glob.glob(path)\n",
    "\n",
    "def readLines(filename):\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        lines = f.read().strip().split('\\n')\n",
    "    return [line.strip() for line in lines]\n",
    "\n",
    "# Load category files from ./data/names/\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "for filename in findFiles('./data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "# Add Finnish surnames to categories\n",
    "category_lines['Finnish'] = surnames\n",
    "\n",
    "# Add 'Finnish' to all_categories if not already present\n",
    "if 'Finnish' not in all_categories:\n",
    "    all_categories.append('Finnish')\n",
    "\n",
    "# Update number of categories\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "# Define the RNN model class\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "# Assuming all_letters and n_letters are already defined in the original notebook\n",
    "all_letters = \"abcdefghijklmnopqrstuvwxyzåäö\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "    rnn.zero_grad()\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return output, loss.item()\n",
    "\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "    return output\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "n_hidden = 256  # Increase the number of hidden units\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=0.001)  # Use Adam optimizer with a learning rate of 0.001\n",
    "\n",
    "# Function to format time since start\n",
    "def time_since(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = int(s / 60)\n",
    "    s -= m * 60\n",
    "    return f'{m}m {s:.2f}s'\n",
    "\n",
    "# Train the model with print statements to show learning progress\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category = random.choice(all_categories)\n",
    "    line = random.choice(category_lines[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(line)\n",
    "\n",
    "    output, loss = train(category_tensor, line_tensor)\n",
    "    current_loss += loss\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = '✓' if guess == category else f'✗ ({category})'\n",
    "        elapsed_time = time_since(start)\n",
    "\n",
    "        # Calculate accuracy over a batch of samples\n",
    "        correct_count = 0\n",
    "        for _ in range(100):\n",
    "            eval_category = random.choice(all_categories)\n",
    "            eval_line = random.choice(category_lines[eval_category])\n",
    "            eval_line_tensor = lineToTensor(eval_line)\n",
    "            eval_output = evaluate(eval_line_tensor)\n",
    "            eval_guess, _ = categoryFromOutput(eval_output)\n",
    "            if eval_guess == eval_category:\n",
    "                correct_count += 1\n",
    "\n",
    "        accuracy = correct_count / 100 * 100\n",
    "\n",
    "        print(f'Iteration: {iter} / {n_iters} ({iter / n_iters * 100:.2f}%)')\n",
    "        print(f'Time elapsed: {elapsed_time}')\n",
    "        print(f'Current loss: {loss:.4f}')\n",
    "        print(f'Name: {line} / Predicted: {guess} {correct}')\n",
    "        print(f'Accuracy over last 100 samples: {accuracy:.2f}%\\n')\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0\n",
    "\n",
    "# Evaluate the model with Finnish surnames\n",
    "correct = 0\n",
    "total = len(category_lines['Finnish'])\n",
    "\n",
    "for surname in category_lines['Finnish']:\n",
    "    output = evaluate(lineToTensor(surname))\n",
    "    guess, _ = categoryFromOutput(output)\n",
    "    if guess == 'Finnish':\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total * 100\n",
    "print(f'Accuracy on Finnish surnames: {accuracy:.2f}%')\n",
    "\n",
    "# Check the model prediction for the user's surname\n",
    "user_surname = \"Alander\"  # Replace with your surname\n",
    "output = evaluate(lineToTensor(user_surname))\n",
    "guess, _ = categoryFromOutput(output)\n",
    "print(f'The model predicts your surname ({user_surname}) as: {guess}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflection\n",
    "\n",
    "1. **How accurate is the neural network?** The accuracy is 68.32%.\n",
    "\n",
    "2. **How many Finnish names does the network predict correctly as Finnish?** The network predicts 68.32% of Finnish names correctly.\n",
    "\n",
    "3. **Try your surname. What does the neural network predict?** When I input my surname \"Alander,\" the neural network predicts it as Arabic.\n",
    "\n",
    "4. **What could be done to improve the neural network performance?** Some possible improvements could include:\n",
    "   - Increasing the size of the training dataset.\n",
    "   - Experimenting with different neural network architectures and hyperparameters.\n",
    "   - Augmenting the data with variations of existing samples.\n",
    "   - Implementing techniques such as dropout regularization to prevent overfitting.\n",
    "   - Training the model for more epochs to allow it to learn more complex patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Käytin tekoälyä avuksi (chatGPT yms.)\n",
    "Tein myös täysin tyhjästä itse koska koin vaikeaksi yhdistää tuohon pohjaan koodia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
